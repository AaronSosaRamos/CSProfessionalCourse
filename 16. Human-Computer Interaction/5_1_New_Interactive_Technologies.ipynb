{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#New Interactive Technologies\n",
        "Implementing different interaction styles (touch, voice) based on user preference."
      ],
      "metadata": {
        "id": "X0H-LW-ZYbdl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def touch_interaction():\n",
        "    print(\"Tap, swipe, or pinch to interact.\")\n",
        "\n",
        "def voice_interaction():\n",
        "    import speech_recognition as sr\n",
        "    r = sr.Recognizer()\n",
        "    with sr.Microphone() as source:\n",
        "        print(\"Speak something...\")\n",
        "        audio = r.listen(source)\n",
        "    try:\n",
        "        print(\"You said: \" + r.recognize_google(audio))\n",
        "    except sr.UnknownValueError:\n",
        "        print(\"Could not understand audio.\")\n",
        "    except sr.RequestError:\n",
        "        print(\"Could not request results.\")\n",
        "\n",
        "# Choosing an interaction style based on user preference\n",
        "user_preference = \"voice\"\n",
        "\n",
        "if user_preference == \"touch\":\n",
        "    touch_interaction()\n",
        "elif user_preference == \"voice\":\n",
        "    voice_interaction()"
      ],
      "metadata": {
        "id": "LSNx26Bhbp4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Approaches for Design, Implementation, and Evaluation of Mouse-less Interaction"
      ],
      "metadata": {
        "id": "qIzVZwKXbrp1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Implementing touch-based and gesture-based interactions."
      ],
      "metadata": {
        "id": "fxakWM-Hbteg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def touch_screen_interaction():\n",
        "    print(\"Use your fingers to interact with the screen.\")\n",
        "\n",
        "def gesture_recognition_interaction():\n",
        "    from pyautogui import gesture\n",
        "    gesture(['down', 'right', 'up'])  # Simulate a gesture\n",
        "\n",
        "# Implementing and evaluating non-mouse interactions\n",
        "current_interaction_method = \"gesture-recognition\"\n",
        "\n",
        "if current_interaction_method == \"touch-screen\":\n",
        "    touch_screen_interaction()\n",
        "elif current_interaction_method == \"gesture-recognition\":\n",
        "    gesture_recognition_interaction()\n"
      ],
      "metadata": {
        "id": "A5kvPx2ebt0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Output: a) Sound b) Stereoscopic Visualization c) Force Feedback Simulation, Haptic Devices"
      ],
      "metadata": {
        "id": "oeEciSOWb0Ga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pygame\n",
        "\n",
        "def play_sound(sound_file):\n",
        "    pygame.mixer.init()\n",
        "    pygame.mixer.music.load(sound_file)\n",
        "    pygame.mixer.music.play()\n",
        "\n",
        "def display_stereoscopic_image(image_path):\n",
        "    # Placeholder for stereoscopic image rendering\n",
        "    print(f\"Displaying stereoscopic image: {image_path}\")\n",
        "\n",
        "def provide_haptic_feedback():\n",
        "    print(\"Applying force feedback...\")\n",
        "\n",
        "# Using different output methods\n",
        "play_sound(\"notification_sound.mp3\")\n",
        "display_stereoscopic_image(\"3d_image.png\")\n",
        "provide_haptic_feedback()"
      ],
      "metadata": {
        "id": "hyHdJHveb0_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#System Architecture: a) Game Engines b) Mobile Augmented Reality c) Flight Simulators d) CAVEs e) Medical Imaging"
      ],
      "metadata": {
        "id": "Fom1l8gJb7aJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pygame  # Example of using a game engine\n",
        "pygame.init()\n",
        "\n",
        "class FlightSimulator:\n",
        "    def __init__(self):\n",
        "        print(\"Flight simulator initialized.\")\n",
        "\n",
        "    def start_simulation(self):\n",
        "        print(\"Flight simulation started.\")\n",
        "\n",
        "def run_cave_system():\n",
        "    print(\"Initializing CAVE system...\")\n",
        "\n",
        "def process_medical_images(images):\n",
        "    print(f\"Processing {len(images)} medical images...\")\n",
        "\n",
        "# Implementing different system architectures\n",
        "game_engine = pygame\n",
        "flight_sim = FlightSimulator()\n",
        "flight_sim.start_simulation()\n",
        "run_cave_system()\n",
        "medical_images = [\"brain_scan.jpg\", \"xray.jpg\"]\n",
        "process_medical_images(medical_images)"
      ],
      "metadata": {
        "id": "zWCLZ6F7b8N7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}