{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Data Science Task with Parallel Processes"
      ],
      "metadata": {
        "id": "aPKqo8TWoIAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Function to perform data science task (e.g., training a model)\n",
        "def perform_data_science_task(data):\n",
        "    X_train, y_train = data[0], data[1]  # Unpack the data tuple\n",
        "    model = RandomForestRegressor(n_estimators=100)\n",
        "    model.fit(X_train, y_train)\n",
        "    return model\n",
        "\n",
        "# Function to split data into chunks for parallel processing\n",
        "def chunk_data(data, num_chunks):\n",
        "    chunk_size = len(data[0]) // num_chunks\n",
        "    chunks = []\n",
        "    for i in range(num_chunks):\n",
        "        start = i * chunk_size\n",
        "        end = (i + 1) * chunk_size if i < num_chunks - 1 else len(data[0])\n",
        "        chunks.append((data[0][start:end], data[1][start:end]))\n",
        "    return chunks\n",
        "\n",
        "# Function to evaluate model\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    return mse\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Example data (random data for demonstration)\n",
        "    num_samples = 1000\n",
        "    num_features = 10\n",
        "    X = np.random.rand(num_samples, num_features)\n",
        "    y = np.random.rand(num_samples)\n",
        "\n",
        "    # Split data into chunks for parallel processing\n",
        "    num_processes = multiprocessing.cpu_count()  # Number of CPU cores\n",
        "    data_chunks = chunk_data((X, y), num_processes)\n",
        "\n",
        "    # Perform data science task (training model) in parallel\n",
        "    with multiprocessing.Pool(processes=num_processes) as pool:\n",
        "        models = pool.map(perform_data_science_task, data_chunks)\n",
        "\n",
        "    # Example test data (random data for demonstration)\n",
        "    num_samples_test = 200\n",
        "    X_test = np.random.rand(num_samples_test, num_features)\n",
        "    y_test = np.random.rand(num_samples_test)\n",
        "\n",
        "    # Evaluate each model\n",
        "    evaluation_results = []\n",
        "    for model in models:\n",
        "        mse = evaluate_model(model, X_test, y_test)\n",
        "        evaluation_results.append(mse)\n",
        "\n",
        "    # Print evaluation results\n",
        "    for i, mse in enumerate(evaluation_results):\n",
        "        print(f\"Model {i+1} MSE: {mse}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hvuNDl3nnfn",
        "outputId": "4e48f752-e461-477e-a8b9-ca18ca3bd597"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 1 MSE: 0.08429601602093935\n",
            "Model 2 MSE: 0.08797028175485362\n"
          ]
        }
      ]
    }
  ]
}