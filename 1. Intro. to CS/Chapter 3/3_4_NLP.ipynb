{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Text Processing"
      ],
      "metadata": {
        "id": "aPKqo8TWoIAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "text = \"Procesamiento de textos es importante para entender el lenguaje natural.\"\n",
        "tokens = nltk.word_tokenize(text)\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hvuNDl3nnfn",
        "outputId": "a2889da5-cde3-4275-f003-566c1a0aa342"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Procesamiento', 'de', 'textos', 'es', 'importante', 'para', 'entender', 'el', 'lenguaje', 'natural', '.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Text Classification"
      ],
      "metadata": {
        "id": "hbpHDI0yvTdQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "texts = [\n",
        "    \"This is a positive review.\",\n",
        "    \"This is a negative review.\",\n",
        "    \"Another positive example.\",\n",
        "    \"Some negative feedback.\",\n",
        "    \"Neutral opinion about the product.\",\n",
        "    \"This product is amazing!\",\n",
        "    \"I hate this product.\",\n",
        "    \"It's okay, not great.\",\n",
        "    \"Best product ever.\",\n",
        "    \"Not worth the money.\",\n",
        "    \"The service was excellent.\",\n",
        "    \"Terrible customer support.\",\n",
        "    \"Highly recommended!\",\n",
        "    \"Very disappointed with the quality.\",\n",
        "    \"Average experience.\",\n",
        "    \"I love this brand.\",\n",
        "    \"Worst purchase I've ever made.\",\n",
        "    \"Could be better.\",\n",
        "    \"Great value for money.\",\n",
        "    \"Completely satisfied with my purchase.\"\n",
        "]\n",
        "labels = [1, 0, 1, 0, 2, 1, 0, 2, 1, 0, 1, 0, 1, 0, 2, 1, 0, 2, 1, 2]\n",
        "\n",
        "# Vectorize text with TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(texts)\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2)\n",
        "\n",
        "# Train classifier\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Test classifier\n",
        "y_pred = clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Cross-validation\n",
        "cv_scores = cross_val_score(clf, X, labels, cv=3)\n",
        "print(\"Cross-Validation Mean Accuracy:\", np.mean(cv_scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6yj6ve-qYaF",
        "outputId": "5e9cf3ff-58bd-4f9f-ae74-680662a6e549"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5\n",
            "Cross-Validation Mean Accuracy: 0.30158730158730157\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#NLP Application (Named Entity Recognition)"
      ],
      "metadata": {
        "id": "JiyOIpfMnlMo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%python -m spacy download es_core_news_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nV9Gat8Dy9th",
        "outputId": "e5e4307f-7699-4513-d838-7538d0bb314c"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting es-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.7.0/es_core_news_sm-3.7.0-py3-none-any.whl (12.9 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.9/12.9 MB 30.9 MB/s eta 0:00:00\n",
            "Requirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from es-core-news-sm==3.7.0) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.6.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.25.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.1.5)\n",
            "Installing collected packages: es-core-news-sm\n",
            "Successfully installed es-core-news-sm-3.7.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuTZEgCsniSi",
        "outputId": "99adac3a-0040-425e-e797-9b8da24b125a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Barack Obama PER\n",
            "Hawaii LOC\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"es_core_news_sm\")\n",
        "text = \"Barack Obama nació en Hawaii.\"\n",
        "doc = nlp(text)\n",
        "\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.label_)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Chatbot Integration"
      ],
      "metadata": {
        "id": "YDVO_noQnwaw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.chat.util import Chat, reflections\n",
        "\n",
        "# Define pairs of patterns and responses\n",
        "pairs = [\n",
        "    [\n",
        "        r\"my name is (.*)\",\n",
        "        [\"Hello %1, how are you today?\",]\n",
        "    ],\n",
        "    [\n",
        "        r\"what is your name?\",\n",
        "        [\"My name is ChatBot and I'm here to help you.\",]\n",
        "    ],\n",
        "    [\n",
        "        r\"how are you?\",\n",
        "        [\"I'm doing well, thank you!\", \"I'm great, thanks for asking!\",]\n",
        "    ],\n",
        "    [\n",
        "        r\"(.*) sorry (.*)\",\n",
        "        [\"It's okay, no worries.\", \"No problem, I understand.\",]\n",
        "    ],\n",
        "    [\n",
        "        r\"(.*) thank you (.*)\",\n",
        "        [\"You're welcome!\", \"No problem. Happy to help!\",]\n",
        "    ],\n",
        "    [\n",
        "        r\"exit\",\n",
        "        [\"Bye! Take care.\", \"Goodbye, have a great day!\",]\n",
        "    ],\n",
        "]\n",
        "\n",
        "# Create a Chat object\n",
        "chatbot = Chat(pairs, reflections)\n",
        "\n",
        "def chatbot_response(input_text):\n",
        "    \"\"\"\n",
        "    Generate a response from the chatbot to the given input text.\n",
        "    \"\"\"\n",
        "    return chatbot.respond(input_text)\n",
        "\n",
        "# Main function to interact with the chatbot\n",
        "def main():\n",
        "    print(\"Hi, I'm ChatBot! How can I assist you today?\")\n",
        "    while True:\n",
        "        user_input = input(\"> \")\n",
        "        response = chatbot_response(user_input)\n",
        "        print(response)\n",
        "        if user_input.lower() == 'exit':\n",
        "            break\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REaFgCJVzyR4",
        "outputId": "1e13438c-c734-4f81-bb8c-9152f1a688cb"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hi, I'm ChatBot! How can I assist you today?\n",
            "> Hi. I want to know more about you\n",
            "None\n",
            "> What is your name?\n",
            "My name is ChatBot and I'm here to help you.\n",
            "> thank you\n",
            "None\n",
            "> how are you?\n",
            "I'm great, thanks for asking!\n",
            "> exit\n",
            "Goodbye, have a great day!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sentiment Analysis"
      ],
      "metadata": {
        "id": "HmPfdnq70w0I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "def analyze_feeling(text):\n",
        "    # Create a TextBlob object\n",
        "    blob = TextBlob(text)\n",
        "\n",
        "    # Get the sentiment polarity\n",
        "    polarity = blob.sentiment.polarity\n",
        "\n",
        "    # Classify the sentiment\n",
        "    if polarity > 0:\n",
        "        return \"Positive\"\n",
        "    elif polarity < 0:\n",
        "        return \"Negative\"\n",
        "    else:\n",
        "        return \"Neutral\"\n",
        "\n",
        "# Example usage:\n",
        "text = \"I love spending time with my friends.\"\n",
        "feeling = analyze_feeling(text)\n",
        "print(\"Feeling:\", feeling)\n",
        "\n",
        "text = \"I hate my life\"\n",
        "feeling = analyze_feeling(text)\n",
        "print(\"Feeling:\", feeling)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sFjpRhg0x_o",
        "outputId": "30a1b126-4233-41fc-e678-01099abfbe87"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feeling: Positive\n",
            "Feeling: Negative\n"
          ]
        }
      ]
    }
  ]
}